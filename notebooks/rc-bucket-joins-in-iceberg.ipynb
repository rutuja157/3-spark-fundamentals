{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf77958-e6da-4848-91bb-d91f4dbd276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are looking at how to do bucket join in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b549b-088b-4230-bffb-7bf54dd19b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "// In python use: from pyspark.sql.functions import broadcast, split, lit\n",
    "import org.apache.spark.sql.functions.{broadcast, split, lit}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a220f77b-d658-489b-88ca-81be2a6431b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports useful functions:\n",
    "# broadcast: For broadcast joins (not used yet, but handy!)\n",
    "# split: To split strings into arrays.\n",
    "# lit: To create literal columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c44bf76-bfc9-4c48-95db-c0ff6d4fd150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matchesBucketed: org.apache.spark.sql.DataFrame = [match_id: string, mapid: string ... 8 more fields]\n",
       "matchDetailsBucketed: org.apache.spark.sql.DataFrame = [match_id: string, player_gamertag: string ... 34 more fields]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val matchesBucketed = spark.read.option(\"header\", \"true\")\n",
    "                        .option(\"inferSchema\", \"true\")\n",
    "                        .csv(\"/home/iceberg/data/matches.csv\")\n",
    "val matchDetailsBucketed =  spark.read.option(\"header\", \"true\")\n",
    "                        .option(\"inferSchema\", \"true\")\n",
    "                        .csv(\"/home/iceberg/data/match_details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51bfd4b-9977-442e-8849-96bc53ca2b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads CSV files and creates Spark DataFrames called matchesBucketed and matchDetailsBucketed.\n",
    "# .option(\"header\", \"true\") means Spark will use the first line as column names.\n",
    "# .option(\"inferSchema\", \"true\") means Spark will try to guess the correct data types for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9f2d827-36a8-42bf-a0d0-7b6e6c1d3f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+--------------------+--------------------+-------------+-------------------+--------------+---------+--------------------+\n",
      "|            match_id|               mapid|is_team_game|         playlist_id|     game_variant_id|is_match_over|    completion_date|match_duration|game_mode|      map_variant_id|\n",
      "+--------------------+--------------------+------------+--------------------+--------------------+-------------+-------------------+--------------+---------+--------------------+\n",
      "|11de1a94-8d07-416...|c7edbf0f-f206-11e...|        true|f72e0ef0-7c4a-430...|1e473914-46e4-408...|         true|2016-02-22 00:00:00|          NULL|     NULL|                NULL|\n",
      "|d3643e71-3e51-43e...|cb914b9e-f206-11e...|       false|d0766624-dbd7-453...|257a305e-4dd3-41f...|         true|2016-02-14 00:00:00|          NULL|     NULL|                NULL|\n",
      "|d78d2aae-36e4-48a...|c7edbf0f-f206-11e...|        true|f72e0ef0-7c4a-430...|1e473914-46e4-408...|         true|2016-03-24 00:00:00|          NULL|     NULL|55e5ee2e-88df-465...|\n",
      "|b440069e-ec5f-4f5...|c7edbf0f-f206-11e...|        true|f72e0ef0-7c4a-430...|1e473914-46e4-408...|         true|2015-12-23 00:00:00|          NULL|     NULL|ec3eef73-13e3-4d4...|\n",
      "|1dd475fc-ee6b-4e1...|c93d708f-f206-11e...|        true|0e39ead4-383b-445...|42f97cca-2cb4-497...|         true|2016-04-07 00:00:00|          NULL|     NULL|                NULL|\n",
      "+--------------------+--------------------+------------+--------------------+--------------------+-------------+-------------------+--------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+---------------+---------------------+------------+-----------------+--------+-----------------+------------------------+------------+---------------------------------+-----------------+----------------+-----------------------+-----------+--------------------------------+----------------+-------------------+---------------+-------------------+------------------+----------------------+--------------------------+-------------------------+------------------------+-------------------------+---------------------------+-------------------------------+--------------------------------+---------------------------+--------------------------------+-------------------------------+-------------------+--------------------+--------------------------+-------+-------+\n",
      "|            match_id|player_gamertag|previous_spartan_rank|spartan_rank|previous_total_xp|total_xp|previous_csr_tier|previous_csr_designation|previous_csr|previous_csr_percent_to_next_tier|previous_csr_rank|current_csr_tier|current_csr_designation|current_csr|current_csr_percent_to_next_tier|current_csr_rank|player_rank_on_team|player_finished|player_average_life|player_total_kills|player_total_headshots|player_total_weapon_damage|player_total_shots_landed|player_total_melee_kills|player_total_melee_damage|player_total_assassinations|player_total_ground_pound_kills|player_total_shoulder_bash_kills|player_total_grenade_damage|player_total_power_weapon_damage|player_total_power_weapon_grabs|player_total_deaths|player_total_assists|player_total_grenade_kills|did_win|team_id|\n",
      "+--------------------+---------------+---------------------+------------+-----------------+--------+-----------------+------------------------+------------+---------------------------------+-----------------+----------------+-----------------------+-----------+--------------------------------+----------------+-------------------+---------------+-------------------+------------------+----------------------+--------------------------+-------------------------+------------------------+-------------------------+---------------------------+-------------------------------+--------------------------------+---------------------------+--------------------------------+-------------------------------+-------------------+--------------------+--------------------------+-------+-------+\n",
      "|71d79b23-4143-435...|      taterbase|                    5|           5|            12537|   13383|                1|                       3|           0|                               98|             NULL|               2|                      3|          0|                              26|            NULL|                  4|          false|        PT14.81149S|                 6|                     4|                     255.0|                       28|                       0|                      0.0|                          0|                              0|                               0|                        0.0|                             0.0|                              0|                 13|                   1|                         0|      1|      1|\n",
      "|71d79b23-4143-435...| SuPeRSaYaInG0D|                   18|          18|           131943|  132557|                2|                       3|           0|                                2|             NULL|               1|                      3|          0|                              76|            NULL|                  7|          false|      PT11.2990845S|                 7|                     3|        350.58792304992676|                       49|                       1|                     45.0|                          0|                              0|                               0|                        0.0|                             0.0|                              0|                 18|                   2|                         0|      0|      0|\n",
      "|71d79b23-4143-435...|       EcZachly|                   21|          21|           168811|  169762|                2|                       5|           0|                               94|             NULL|               3|                      5|          0|                              24|            NULL|                  3|          false|      PT19.1357063S|                12|                    12|                     625.0|                       43|                       0|                      0.0|                          0|                              0|                               0|                        0.0|                             0.0|                              0|                 10|                   4|                         0|      1|      1|\n",
      "|71d79b23-4143-435...|    johnsnake04|                   14|          14|            64073|   64639|             NULL|                    NULL|        NULL|                             NULL|             NULL|            NULL|                   NULL|       NULL|                            NULL|            NULL|                  6|          false|      PT21.1521599S|                13|                    13|                     605.0|                       24|                       0|                      0.0|                          0|                              0|                               0|                        0.0|                             0.0|                              0|                  9|                   2|                         0|      0|      0|\n",
      "|71d79b23-4143-435...| Super Mac Bros|                   26|          26|           243425|  244430|                1|                       5|           0|                               86|             NULL|               2|                      5|          0|                               8|            NULL|                  2|          false|      PT12.8373793S|                13|                    12|                     595.0|                       32|                       1|       20.004501342773438|                          0|                              0|                               0|                        0.0|                             0.0|                              0|                 15|                   2|                         0|      1|      1|\n",
      "+--------------------+---------------+---------------------+------------+-----------------+--------+-----------------+------------------------+------------+---------------------------------+-----------------+----------------+-----------------------+-----------+--------------------------------+----------------+-------------------+---------------+-------------------+------------------+----------------------+--------------------------+-------------------------+------------------------+-------------------------+---------------------------+-------------------------------+--------------------------------+---------------------------+--------------------------------+-------------------------------+-------------------+--------------------+--------------------------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matchesBucketed.show(5)        // Show 5 rows from matchesBucketed\n",
    "matchDetailsBucketed.show(5)   // Show 5 rows from matchDetailsBucketed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6891cf71-ce30-405c-ac77-6997000e440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- match_id: string (nullable = true)\n",
      " |-- mapid: string (nullable = true)\n",
      " |-- is_team_game: boolean (nullable = true)\n",
      " |-- playlist_id: string (nullable = true)\n",
      " |-- game_variant_id: string (nullable = true)\n",
      " |-- is_match_over: boolean (nullable = true)\n",
      " |-- completion_date: timestamp (nullable = true)\n",
      " |-- match_duration: string (nullable = true)\n",
      " |-- game_mode: string (nullable = true)\n",
      " |-- map_variant_id: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- match_id: string (nullable = true)\n",
      " |-- player_gamertag: string (nullable = true)\n",
      " |-- previous_spartan_rank: integer (nullable = true)\n",
      " |-- spartan_rank: integer (nullable = true)\n",
      " |-- previous_total_xp: integer (nullable = true)\n",
      " |-- total_xp: integer (nullable = true)\n",
      " |-- previous_csr_tier: integer (nullable = true)\n",
      " |-- previous_csr_designation: integer (nullable = true)\n",
      " |-- previous_csr: integer (nullable = true)\n",
      " |-- previous_csr_percent_to_next_tier: integer (nullable = true)\n",
      " |-- previous_csr_rank: integer (nullable = true)\n",
      " |-- current_csr_tier: integer (nullable = true)\n",
      " |-- current_csr_designation: integer (nullable = true)\n",
      " |-- current_csr: integer (nullable = true)\n",
      " |-- current_csr_percent_to_next_tier: integer (nullable = true)\n",
      " |-- current_csr_rank: integer (nullable = true)\n",
      " |-- player_rank_on_team: integer (nullable = true)\n",
      " |-- player_finished: boolean (nullable = true)\n",
      " |-- player_average_life: string (nullable = true)\n",
      " |-- player_total_kills: integer (nullable = true)\n",
      " |-- player_total_headshots: integer (nullable = true)\n",
      " |-- player_total_weapon_damage: double (nullable = true)\n",
      " |-- player_total_shots_landed: integer (nullable = true)\n",
      " |-- player_total_melee_kills: integer (nullable = true)\n",
      " |-- player_total_melee_damage: double (nullable = true)\n",
      " |-- player_total_assassinations: integer (nullable = true)\n",
      " |-- player_total_ground_pound_kills: integer (nullable = true)\n",
      " |-- player_total_shoulder_bash_kills: integer (nullable = true)\n",
      " |-- player_total_grenade_damage: double (nullable = true)\n",
      " |-- player_total_power_weapon_damage: double (nullable = true)\n",
      " |-- player_total_power_weapon_grabs: integer (nullable = true)\n",
      " |-- player_total_deaths: integer (nullable = true)\n",
      " |-- player_total_assists: integer (nullable = true)\n",
      " |-- player_total_grenade_kills: integer (nullable = true)\n",
      " |-- did_win: integer (nullable = true)\n",
      " |-- team_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matchesBucketed.printSchema()        // See columns and data types\n",
    "matchDetailsBucketed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a03a927e-0209-4e84-b2ec-e30af8d2c0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Long = 151761\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchesBucketed.count()              // Total number of rows\n",
    "matchDetailsBucketed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a03ed5-eed6-44ee-8074-e48db96cf894",
   "metadata": {},
   "outputs": [],
   "source": [
    "these 2 files have shared key match_id that they can join on, we are looking on match_id to be the join key\n",
    "for this iceberg table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82b56e33-57d1-4f69-914f-27ee3a098aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bucketedDDL: String =\n",
       "\"\n",
       "CREATE TABLE IF NOT EXISTS bootcamp.matches_bucketed (\n",
       "     match_id STRING,\n",
       "     is_team_game BOOLEAN,\n",
       "     playlist_id STRING,\n",
       "     completion_date TIMESTAMP\n",
       " )\n",
       " USING iceberg\n",
       " PARTITIONED BY (completion_date, bucket(16, match_id));\n",
       " \"\n",
       "res4: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"DROP TABLE IF EXISTS bootcamp.matches_bucketed\"\"\")\n",
    "val bucketedDDL = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bootcamp.matches_bucketed (\n",
    "     match_id STRING,\n",
    "     is_team_game BOOLEAN,\n",
    "     playlist_id STRING,\n",
    "     completion_date TIMESTAMP\n",
    " )\n",
    " USING iceberg\n",
    " PARTITIONED BY (completion_date, bucket(16, match_id));\n",
    " \"\"\"\n",
    " spark.sql(bucketedDDL\n",
    "\n",
    "#  define new table and This means it uses Apache Iceberg, a modern table format for big data.\n",
    "# PARTITIONED BY: date and buckets (this will give us ability to work with this data)\n",
    "# First by completion_date (for time-based partitioning)\n",
    "# Then by bucket(16, match_id) (bucketing)\n",
    "# (Divides data into 16 buckets based on match_id hash value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a159731-da35-40cd-8796-309ba48697fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "| bootcamp|              events|      false|\n",
      "| bootcamp|events_aggregated...|      false|\n",
      "| bootcamp|       events_sorted|      false|\n",
      "| bootcamp|    events_sorted_v2|      false|\n",
      "| bootcamp|     events_unsorted|      false|\n",
      "| bootcamp|  events_unsorted_v2|      false|\n",
      "| bootcamp|    matches_bucketed|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//If you want to double-check that it’s gone, you can list tables in the database:\n",
    "spark.sql(\"SHOW TABLES IN bootcamp\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d0d40-414e-422c-ab87-be5902ccba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Why bucket?\n",
    "When you join with another table bucketed on the same column and same number of buckets, Spark can optimize the join to avoid shuffling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e52a6d53-d4de-4bd6-98a8-a96401b8354b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-------------------------------------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                                              |comment|\n",
      "+----------------------------+-------------------------------------------------------------------------------------------------------+-------+\n",
      "|match_id                    |string                                                                                                 |NULL   |\n",
      "|is_team_game                |boolean                                                                                                |NULL   |\n",
      "|playlist_id                 |string                                                                                                 |NULL   |\n",
      "|completion_date             |timestamp                                                                                              |NULL   |\n",
      "|                            |                                                                                                       |       |\n",
      "|# Partitioning              |                                                                                                       |       |\n",
      "|Part 0                      |completion_date                                                                                        |       |\n",
      "|Part 1                      |bucket(16, match_id)                                                                                   |       |\n",
      "|                            |                                                                                                       |       |\n",
      "|# Metadata Columns          |                                                                                                       |       |\n",
      "|_spec_id                    |int                                                                                                    |       |\n",
      "|_partition                  |struct<completion_date:timestamp,match_id_bucket:int>                                                  |       |\n",
      "|_file                       |string                                                                                                 |       |\n",
      "|_pos                        |bigint                                                                                                 |       |\n",
      "|_deleted                    |boolean                                                                                                |       |\n",
      "|                            |                                                                                                       |       |\n",
      "|# Detailed Table Information|                                                                                                       |       |\n",
      "|Name                        |demo.bootcamp.matches_bucketed                                                                         |       |\n",
      "|Type                        |MANAGED                                                                                                |       |\n",
      "|Location                    |s3://warehouse/bootcamp/matches_bucketed                                                               |       |\n",
      "|Provider                    |iceberg                                                                                                |       |\n",
      "|Owner                       |root                                                                                                   |       |\n",
      "|Table Properties            |[current-snapshot-id=none,format=iceberg/parquet,format-version=2,write.parquet.compression-codec=zstd]|       |\n",
      "+----------------------------+-------------------------------------------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// See the table structure (columns, partitioning)\n",
    "spark.sql(\"DESCRIBE FORMATTED bootcamp.matches_bucketed\").show(100, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fae76e-9740-4a28-a0b8-b8a28cd92a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "  matchesBucketed.select(\n",
    "     $\"match_id\", $\"is_team_game\", $\"playlist_id\", $\"completion_date\"\n",
    "     )\n",
    "    .write.mode(\"append\")\n",
    "    .partitionBy(\"completion_date\")\n",
    "  .bucketBy(16, \"match_id\").saveAsTable(\"bootcamp.matches_bucketed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d823ba-3e84-4f36-9d63-3ea83bd5154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is how we are going to writeout the data into the buckets\n",
    "# matchesBucketed.select(...)\n",
    "# Selects only the columns you want to write into the new table.\n",
    "\n",
    "# .write\n",
    "# Tells Spark you want to write the DataFrame somewhere.\n",
    "\n",
    "# .mode(\"append\")\n",
    "# Adds the data to the table if it already exists (doesn’t overwrite).\n",
    "\n",
    "# .partitionBy(\"completion_date\")\n",
    "# Partitions the table by completion_date — files will be organized by date.\n",
    "\n",
    "# .bucketBy(16, \"match_id\")\n",
    "# Buckets the data into 16 files based on a hash of match_id.\n",
    "# (This matches your table definition. Bucketing improves join performance.)\n",
    "\n",
    "# .saveAsTable(\"bootcamp.matches_bucketed\")\n",
    "# Actually writes the data to the Iceberg table you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c32ea0-6f58-4cd7-8814-d8acf7a40bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.table(\"bootcamp.matches_bucketed\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0c169-d536-47be-a19e-f1da7ab2dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.table(\"bootcamp.matches_bucketed\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea22951-096b-447c-8f9f-64b861637d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW PARTITIONS bootcamp.matches_bucketed\").show(100, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf722f3-68d9-4c59-8428-3effaebaa864",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT completion_date, COUNT(*) \n",
    "  FROM bootcamp.matches_bucketed \n",
    "  GROUP BY completion_date\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b053c01-c5a1-400a-91c9-b6afd1884884",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " val bucketedDetailsDDL = \"\"\"\n",
    " CREATE TABLE IF NOT EXISTS bootcamp.match_details_bucketed (\n",
    "     match_id STRING,\n",
    "     player_gamertag STRING,\n",
    "     player_total_kills INTEGER,\n",
    "     player_total_deaths INTEGER\n",
    " )\n",
    " USING iceberg\n",
    " PARTITIONED BY (bucket(16, match_id));\n",
    " \"\"\"\n",
    "spark.sql(bucketedDetailsDDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab08197-db55-43c2-88f5-6ecc6cece888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  creating another bucketed table for your match details! \n",
    "#  Instead of traditional partitions, you’re just bucketing this table by match_id into 16 buckets.\n",
    "\n",
    "# No date-based partitioning here, just bucketing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba2311-521a-419f-bc8c-77ba70696ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW TABLES IN bootcamp\").show()\n",
    "\n",
    "spark.sql(\"DESCRIBE FORMATTED bootcamp.match_details_bucketed\").show(100, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b28890-1e0f-4eb6-b6d6-a6fc57bb2f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. See if buckets are recognized (partitions column will mention buckets)\n",
    "# In the output of DESCRIBE FORMATTED, look under # Partitioning — you should see info about the bucketing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66730e79-ea7e-4cac-b067-952b18a41134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is this important?\n",
    "# Now both tables (matches_bucketed and match_details_bucketed) are bucketed by match_id with the same number of buckets.\n",
    "\n",
    "# This sets you up for a bucketed join, which is faster because Spark can join files directly without shuffling data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f679b2-ad92-4c18-a6eb-51786a94ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    " matchDetailsBucketed.select(\n",
    "     $\"match_id\", $\"player_gamertag\", $\"player_total_kills\", $\"player_total_deaths\")\n",
    "     .write.mode(\"append\")\n",
    "   .bucketBy(16, \"match_id\").saveAsTable(\"bootcamp.match_details_bucketed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a45566b-44ca-448c-8b92-6d4558ca2b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "we are essentially moving data from csv files to bucketed iceberg table, if we bucket things we dont have to shuffle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a956dc56-c653-41ea-a7b0-695574e13da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ba757f-819a-40d6-a6a8-c0c15155cb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eb8091-3c83-4d2a-b133-b8dfbd0dc878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374411c5-a48f-4739-9031-d638638633a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://b79bc3db1652:4041\n",
       "SparkContext available as 'sc' (version = 3.5.5, master = local[*], app id = local-1753646333178)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "org.apache.spark.sql.catalyst.ExtendedAnalysisException",
     "evalue": " [TABLE_OR_VIEW_NOT_FOUND] The table or view `bootcamp`.`match_details_bucketed` cannot be found. Verify the spelling and correctness of the schema and catalog.",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `bootcamp`.`match_details_bucketed` cannot be found. Verify the spelling and correctness of the schema and catalog.",
      "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.",
      "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 18;",
      "'Project [*]",
      "+- 'Join Inner, (('mdb.match_id = 'md.match_id) AND ('md.completion_date = cast(2016-01-01 as date)))",
      "   :- 'SubqueryAlias mdb",
      "   :  +- 'UnresolvedRelation [bootcamp, match_details_bucketed], [], false",
      "   +- SubqueryAlias md",
      "      +- SubqueryAlias demo.bootcamp.matches_bucketed",
      "         +- RelationV2[match_id#126, is_team_game#127, playlist_id#128, completion_date#129] demo.bootcamp.matches_bucketed demo.bootcamp.matches_bucketed",
      "",
      "  at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.tableNotFound(package.scala:87)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:235)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:215)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:244)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:243)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:243)",
      "  at scala.collection.Iterator.foreach(Iterator.scala:943)",
      "  at scala.collection.Iterator.foreach$(Iterator.scala:943)",
      "  at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)",
      "  at scala.collection.IterableLike.foreach(IterableLike.scala:74)",
      "  at scala.collection.IterableLike.foreach$(IterableLike.scala:73)",
      "  at scala.collection.AbstractIterable.foreach(Iterable.scala:56)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:243)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:243)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:243)",
      "  at scala.collection.Iterator.foreach(Iterator.scala:943)",
      "  at scala.collection.Iterator.foreach$(Iterator.scala:943)",
      "  at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)",
      "  at scala.collection.IterableLike.foreach(IterableLike.scala:74)",
      "  at scala.collection.IterableLike.foreach$(IterableLike.scala:73)",
      "  at scala.collection.AbstractIterable.foreach(Iterable.scala:56)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:243)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:243)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:243)",
      "  at scala.collection.Iterator.foreach(Iterator.scala:943)",
      "  at scala.collection.Iterator.foreach$(Iterator.scala:943)",
      "  at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)",
      "  at scala.collection.IterableLike.foreach(IterableLike.scala:74)",
      "  at scala.collection.IterableLike.foreach$(IterableLike.scala:73)",
      "  at scala.collection.AbstractIterable.foreach(Iterable.scala:56)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:243)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:215)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:197)",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:202)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:193)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:171)",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:202)",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:225)",
      "  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)",
      "  at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)",
      "  at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)",
      "  at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)",
      "  at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)",
      "  at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)",
      "  at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)",
      "  at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)",
      "  at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)",
      "  at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)",
      "  at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)",
      "  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)",
      "  at org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:691)",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)",
      "  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:682)",
      "  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:713)",
      "  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:744)",
      "  ... 38 elided",
      ""
     ]
    }
   ],
   "source": [
    "\n",
    "// In python use: from pyspark.sql.functions import broadcast, split, lit\n",
    "import org.apache.spark.sql.functions.{broadcast, split, lit}\n",
    "\n",
    "\n",
    "val matchesBucketed = spark.read.option(\"header\", \"true\")\n",
    "                        .option(\"inferSchema\", \"true\")\n",
    "                        .csv(\"/home/iceberg/data/matches.csv\")\n",
    "val matchDetailsBucketed =  spark.read.option(\"header\", \"true\")\n",
    "                        .option(\"inferSchema\", \"true\")\n",
    "                        .csv(\"/home/iceberg/data/match_details.csv\")\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"DROP TABLE IF EXISTS bootcamp.matches_bucketed\"\"\")\n",
    "val bucketedDDL = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bootcamp.matches_bucketed (\n",
    "     match_id STRING,\n",
    "     is_team_game BOOLEAN,\n",
    "     playlist_id STRING,\n",
    "     completion_date TIMESTAMP\n",
    " )\n",
    " USING iceberg\n",
    " PARTITIONED BY (completion_date, bucket(16, match_id));\n",
    " \"\"\"\n",
    " spark.sql(bucketedDDL)\n",
    "\n",
    "// matchesBucketed.select(\n",
    "//     $\"match_id\", $\"is_team_game\", $\"playlist_id\", $\"completion_date\"\n",
    "//     )\n",
    "//     .write.mode(\"append\")\n",
    "//     .partitionBy(\"completion_date\")\n",
    "//   .bucketBy(16, \"match_id\").saveAsTable(\"bootcamp.matches_bucketed\")\n",
    "\n",
    "\n",
    "// val bucketedDetailsDDL = \"\"\"\n",
    "// CREATE TABLE IF NOT EXISTS bootcamp.match_details_bucketed (\n",
    "//     match_id STRING,\n",
    "//     player_gamertag STRING,\n",
    "//     player_total_kills INTEGER,\n",
    "//     player_total_deaths INTEGER\n",
    "// )\n",
    "// USING iceberg\n",
    "// PARTITIONED BY (bucket(16, match_id));\n",
    "// \"\"\"\n",
    "// spark.sql(bucketedDetailsDDL)\n",
    "\n",
    "// matchDetailsBucketed.select(\n",
    "//     $\"match_id\", $\"player_gamertag\", $\"player_total_kills\", $\"player_total_deaths\")\n",
    "//     .write.mode(\"append\")\n",
    "//   .bucketBy(16, \"match_id\").saveAsTable(\"bootcamp.match_details_bucketed\")\n",
    "\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n",
    "\n",
    "matchesBucketed.createOrReplaceTempView(\"matches\")\n",
    "matchDetailsBucketed.createOrReplaceTempView(\"match_details\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM bootcamp.match_details_bucketed mdb JOIN bootcamp.matches_bucketed md \n",
    "    ON mdb.match_id = md.match_id\n",
    "    AND md.completion_date = DATE('2016-01-01')\n",
    "        \n",
    "\"\"\").explain()\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM match_details mdb JOIN matches md ON mdb.match_id = md.match_id\n",
    "        \n",
    "\"\"\").explain()\n",
    "\n",
    "// spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"1000000000000\")\n",
    "\n",
    "// val broadcastFromThreshold = matches.as(\"m\").join(matchDetails.as(\"md\"), $\"m.match_id\" === $\"md.match_id\")\n",
    "//   .select($\"m.completion_date\", $\"md.player_gamertag\",  $\"md.player_total_kills\")\n",
    "//   .take(5)\n",
    "\n",
    "// val explicitBroadcast = matches.as(\"m\").join(broadcast(matchDetails).as(\"md\"), $\"m.match_id\" === $\"md.match_id\")\n",
    "//   .select($\"md.*\", split($\"completion_date\", \" \").getItem(0).as(\"ds\"))\n",
    "\n",
    "// val bucketedValues = matchDetailsBucketed.as(\"mdb\").join(matchesBucketed.as(\"mb\"), $\"mb.match_id\" === $\"mdb.match_id\").explain()\n",
    "// // .take(5)\n",
    "\n",
    "// val values = matchDetailsBucketed.as(\"m\").join(matchesBucketed.as(\"md\"), $\"m.match_id\" === $\"md.match_id\").explain()\n",
    "\n",
    "// explicitBroadcast.write.mode(\"overwrite\").insertInto(\"match_details_bucketed\")\n",
    "\n",
    "// matches.withColumn(\"ds\", split($\"completion_date\", \" \").getItem(0)).write.mode(\"overwrite\").insertInto(\"matches_bucketed\")\n",
    "\n",
    "// spark.sql(bucketedSQL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8adb02-d5bd-4e84-a671-48991772d233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1eecb6-ca9a-4b5c-b046-b3a0dd1ff3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
